{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7rpHQfvpZyg",
        "outputId": "93fae2d2-d651-41cb-fa4a-44ca9086d2f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting wfdb\n",
            "  Downloading wfdb-4.1.0-py3-none-any.whl (159 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.9/159.9 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting neurokit2\n",
            "  Downloading neurokit2-0.2.3-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mne\n",
            "  Downloading mne-1.3.1-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m78.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coral-ordinal\n",
            "  Downloading coral_ordinal-0.1.8-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from wfdb) (2.27.1)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wfdb) (1.10.1)\n",
            "Requirement already satisfied: pandas<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wfdb) (1.4.4)\n",
            "Collecting SoundFile<0.12.0,>=0.10.0\n",
            "  Downloading soundfile-0.11.0-py2.py3-none-any.whl (23 kB)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.10.1 in /usr/local/lib/python3.9/dist-packages (from wfdb) (1.22.4)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.2.2 in /usr/local/lib/python3.9/dist-packages (from wfdb) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from neurokit2) (1.2.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from mne) (4.65.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from mne) (23.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from mne) (3.1.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from mne) (4.4.2)\n",
            "Requirement already satisfied: pooch>=1.5 in /usr/local/lib/python3.9/dist-packages (from mne) (1.6.0)\n",
            "Requirement already satisfied: tensorflow>=2.2 in /usr/local/lib/python3.9/dist-packages (from coral-ordinal) (2.12.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (2.8.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (8.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (0.11.0)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (5.12.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (4.39.3)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib<4.0.0,>=3.2.2->wfdb) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas<2.0.0,>=1.0.0->wfdb) (2022.7.1)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from pooch>=1.5->mne) (1.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.8.1->wfdb) (2022.12.7)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->neurokit2) (1.1.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=1.0.0->neurokit2) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/dist-packages (from SoundFile<0.12.0,>=0.10.0->wfdb) (1.15.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (4.5.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (0.2.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (1.6.3)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (3.20.3)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (1.14.1)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (23.3.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (1.53.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (67.6.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (0.4.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (0.4.7)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (0.32.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (2.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (3.3.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (1.4.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (2.12.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (1.16.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (3.8.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.2->coral-ordinal) (16.0.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->mne) (2.1.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow>=2.2->coral-ordinal) (0.40.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0->SoundFile<0.12.0,>=0.10.0->wfdb) (2.21)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib<4.0.0,>=3.2.2->wfdb) (3.15.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow>=2.2->coral-ordinal) (0.0.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2->coral-ordinal) (0.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2->coral-ordinal) (3.4.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2->coral-ordinal) (0.4.6)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2->coral-ordinal) (2.17.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2->coral-ordinal) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.2->coral-ordinal) (1.8.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2->coral-ordinal) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2->coral-ordinal) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2->coral-ordinal) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow>=2.2->coral-ordinal) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow>=2.2->coral-ordinal) (6.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.2->coral-ordinal) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.13,>=2.12->tensorflow>=2.2->coral-ordinal) (3.2.2)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9676 sha256=3da96e3d596140fc28f011bd0119cb9e20132117f7fe0da327debc7e54acc64a\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/5f/3e/46cc37c5d698415694d83f607f833f83f0149e49b3af9d0f38\n",
            "Successfully built wget\n",
            "Installing collected packages: wget, SoundFile, wfdb, neurokit2, mne, coral-ordinal\n",
            "  Attempting uninstall: SoundFile\n",
            "    Found existing installation: soundfile 0.12.1\n",
            "    Uninstalling soundfile-0.12.1:\n",
            "      Successfully uninstalled soundfile-0.12.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "librosa 0.10.0.post2 requires soundfile>=0.12.1, but you have soundfile 0.11.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed SoundFile-0.11.0 coral-ordinal-0.1.8 mne-1.3.1 neurokit2-0.2.3 wfdb-4.1.0 wget-3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install wget wfdb neurokit2 mne coral-ordinal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ZJuKV5Hpb0U",
        "outputId": "f86c6e52-0b6a-4b4f-ff6b-e704d9f3c414"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kaggle.json\n"
          ]
        }
      ],
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!ls ~/.kaggle\n",
        "!chmod 600 /root/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYqWe-76pgJt",
        "outputId": "20204895-4f72-4a32-f2e1-194f1ba0a34b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading george-moody-2023-complete-dataset.zip to /content\n",
            "100% 17.4G/17.4G [15:42<00:00, 21.2MB/s]\n",
            "100% 17.4G/17.4G [15:42<00:00, 19.8MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download -d bjoernjostein/george-moody-2023-complete-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f9BA35CKz8AY",
        "outputId": "ed890856-d970-4f65-c5f2-5aeff57ff0bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting GitPython\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 KB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 KB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, gitdb, GitPython\n",
            "Successfully installed GitPython-3.1.31 gitdb-4.0.10 smmap-5.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install GitPython\n",
        "from git import Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0bbUuZ69E76X"
      },
      "outputs": [],
      "source": [
        "access_token = \"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\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vHCXdEQDD7Ci"
      },
      "outputs": [],
      "source": [
        "HTTPS_REMOTE_URL = 'https://' + access_token + ':x-oauth-basic@github.com/Bsingstad/EEG-predict-cardiac-arrest-recovery'\n",
        "DEST_NAME = 'repo'\n",
        "cloned_repo = Repo.clone_from(HTTPS_REMOTE_URL, DEST_NAME, branch=\"batch_gen_1d\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext autoreload\n",
        "%autoreload\n",
        "%reload_ext autoreload"
      ],
      "metadata": {
        "id": "z0Dve_Bu91PF",
        "outputId": "7325413a-f1ee-4731-d21c-08efb63da787",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "0wkCjnFB0QOW"
      },
      "outputs": [],
      "source": [
        "from repo.helper_code import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "4ejmx0YoSkKA"
      },
      "outputs": [],
      "source": [
        "def replace_line(file_name, line_num, text):\n",
        "    lines = open(file_name, 'r').readlines()\n",
        "    lines[line_num] = text\n",
        "    out = open(file_name, 'w')\n",
        "    out.writelines(lines)\n",
        "    out.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {
        "id": "jbKTepIhF3xC"
      },
      "outputs": [],
      "source": [
        "replace_line('/content/repo/evaluate_model.py',15,\"from repo.helper_code import * \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "q0sWcdDJkCO5"
      },
      "outputs": [],
      "source": [
        "from repo.evaluate_model import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {
        "id": "xNoId8s2ScOl"
      },
      "outputs": [],
      "source": [
        "replace_line('/content/repo/team_code.py',11,\"from repo.helper_code import * \\n\")\n",
        "replace_line('/content/repo/team_code.py',12,\"from repo.evaluate_model import * \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "id": "HF93NC9bSDej"
      },
      "outputs": [],
      "source": [
        "from repo.team_code import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {
        "id": "aIrxYUSSXocd"
      },
      "outputs": [],
      "source": [
        "replace_line('/content/repo/run_model.py',12,\"from repo.helper_code import * \\n\")\n",
        "replace_line('/content/repo/run_model.py',13,\"from repo.team_code import load_challenge_models, run_challenge_models \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {
        "id": "hPD9Nlw9Xjl8"
      },
      "outputs": [],
      "source": [
        "from repo.run_model import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {
        "id": "quSp-rnhvG4T"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib\n",
        "\n",
        "font = {'size'   : 16}\n",
        "\n",
        "matplotlib.rc('font', **font)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "lwW5eIAPHBL1"
      },
      "outputs": [],
      "source": [
        "dir_name = \"./\"\n",
        "extension = \".zip\"\n",
        " \n",
        "os.chdir(dir_name) # change directory from working dir to dir with files\n",
        "\n",
        "for item in os.listdir(dir_name): # loop through items in dir\n",
        "    if item.endswith(extension): # check for \".zip\" extension\n",
        "        file_name = os.path.abspath(item) # get full path of files\n",
        "        zip_ref = zipfile.ZipFile(file_name) # create zipfile object\n",
        "        zip_ref.extractall(dir_name) # extract file to dir\n",
        "        zip_ref.close() # close file\n",
        "        os.remove(file_name) # delete zipped file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "YtwJOLLDHI5e"
      },
      "outputs": [],
      "source": [
        "os.rename(\"./i-care-international-cardiac-arrest-research-consortium-database-1.0/\", \"./data/\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_folds = 5"
      ],
      "metadata": {
        "id": "AtKWK9mLBlhs"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"/content/data/training/\""
      ],
      "metadata": {
        "id": "t2SMPh1A-__r"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "patient_ids = find_data_folders(data_folder)"
      ],
      "metadata": {
        "id": "60poBKk1-7nf"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames = get_valid_filenames_from_patient_ids(data_folder,patient_ids)"
      ],
      "metadata": {
        "id": "ucV68VlQ_FwN"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filenames[0].split(\"/\")[-2]"
      ],
      "metadata": {
        "id": "Xsc-hUrt_HV3",
        "outputId": "67566e70-1d3d-4bf3-ab62-ca0c1daee56a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ICARE_0284'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y5HrNIUQGJFp",
        "outputId": "de64422e-112b-4c57-c0eb-577a5adbf255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finding the Challenge data...\n",
            "Extracting features and labels from the Challenge data...\n",
            "Split the data into 5 cross-validation folds\n",
            "Fold 0:\n",
            "Inception model built.\n",
            "Training the Challenge models on the Challenge data...\n",
            "Epoch 1/15\n",
            "  14/1251 [..............................] - ETA: 50:59 - loss: 1.3118 - mean_absolute_error_labels: 0.6995"
          ]
        },
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-127-8ba81d30df49>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mall_preds_outcome\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mall_labels_outcome\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mchallenge_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauroc_outcomes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauprc_outcomes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_outcomes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_measure_outcomes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmse_cpcs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmae_cpcs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/data/training/\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_folds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/repo/team_code.py\u001b[0m in \u001b[0;36mcross_validate_model\u001b[0;34m(data_folder, num_folds, verbose)\u001b[0m\n\u001b[1;32m    200\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Training the Challenge models on the Challenge data...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         cpc_model.fit(x = batch_generator(batch_size=BATCH_SIZE, gen = generate_data(data_folder, train_filenames)), epochs=EPOCHS, \n\u001b[0m\u001b[1;32m    203\u001b[0m                                               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_filenames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m                                               steps_per_epoch=len(train_filenames)/BATCH_SIZE, validation_steps=len(val_filenames)/BATCH_SIZE,validation_freq=1)\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: Graph execution error:\n\nDetected at node 'gradient_tape/model_5/batch_normalization_47/moments/BroadcastTo_1' defined at (most recent call last):\n    File \"/usr/lib/python3.9/runpy.py\", line 197, in _run_module_as_main\n      return _run_code(code, main_globals, None,\n    File \"/usr/lib/python3.9/runpy.py\", line 87, in _run_code\n      exec(code, run_globals)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel_launcher.py\", line 16, in <module>\n      app.launch_new_instance()\n    File \"/usr/local/lib/python3.9/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n      app.start()\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelapp.py\", line 619, in start\n      self.io_loop.start()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/platform/asyncio.py\", line 215, in start\n      self.asyncio_loop.run_forever()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 601, in run_forever\n      self._run_once()\n    File \"/usr/lib/python3.9/asyncio/base_events.py\", line 1905, in _run_once\n      handle._run()\n    File \"/usr/lib/python3.9/asyncio/events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 687, in <lambda>\n      lambda f: self._run_callback(functools.partial(callback, future))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/ioloop.py\", line 740, in _run_callback\n      ret = callback()\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 821, in inner\n      self.ctx_run(self.run)\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 782, in run\n      yielded = self.gen.send(value)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 361, in process_one\n      yield gen.maybe_future(dispatch(*args))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 261, in dispatch_shell\n      yield gen.maybe_future(handler(stream, idents, msg))\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/kernelbase.py\", line 539, in execute_request\n      self.do_execute(\n    File \"/usr/local/lib/python3.9/dist-packages/tornado/gen.py\", line 234, in wrapper\n      yielded = ctx_run(next, result)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/ipkernel.py\", line 302, in do_execute\n      res = shell.run_cell(code, store_history=store_history, silent=silent)\n    File \"/usr/local/lib/python3.9/dist-packages/ipykernel/zmqshell.py\", line 539, in run_cell\n      return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n      result = self._run_cell(\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n      return runner(coro)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n      coro.send(None)\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n      if (await self.run_code(code, result,  async_=asy)):\n    File \"/usr/local/lib/python3.9/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"<ipython-input-127-8ba81d30df49>\", line 1, in <cell line: 1>\n      all_preds_outcome , all_labels_outcome , challenge_score, auroc_outcomes, auprc_outcomes, accuracy_outcomes, f_measure_outcomes, mse_cpcs, mae_cpcs = cross_validate_model(\"/content/data/training/\",num_folds,1)\n    File \"/content/repo/team_code.py\", line 202, in cross_validate_model\n      cpc_model.fit(x = batch_generator(batch_size=BATCH_SIZE, gen = generate_data(data_folder, train_filenames)), epochs=EPOCHS,\n    File \"/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1054, in train_step\n      self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer.py\", line 542, in minimize\n      grads_and_vars = self.compute_gradients(loss, var_list, tape)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer.py\", line 275, in compute_gradients\n      grads = tape.gradient(loss, var_list)\nNode: 'gradient_tape/model_5/batch_normalization_47/moments/BroadcastTo_1'\nOOM when allocating tensor with shape[225,3000,128] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node gradient_tape/model_5/batch_normalization_47/moments/BroadcastTo_1}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info. This isn't available when running in Eager mode.\n [Op:__inference_train_function_29891]"
          ]
        }
      ],
      "source": [
        "all_preds_outcome , all_labels_outcome , challenge_score, auroc_outcomes, auprc_outcomes, accuracy_outcomes, f_measure_outcomes, mse_cpcs, mae_cpcs = cross_validate_model(\"/content/data/training/\",num_folds,1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install neptune"
      ],
      "metadata": {
        "id": "OfQmRhFiAzQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import neptune\n",
        "\n",
        "run = neptune.init_run(\n",
        "    project=\"SSCP/George-Moody-Challenge-2023\",\n",
        "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIzMGUyN2Q2ZS05MjVkLTRlMzItODYwZS0yODQ3ZWU3ZTdmMmEifQ==\",\n",
        ")  # your credentials\n",
        "\n",
        "run[\"Model\"] = \"Inception\"\n",
        "run[\"Task\"] = 5\n",
        "run[\"Use_demography\"] = \"no\"\n",
        "run[\"cross_val\"] =\"yes\"\n",
        "for i in range(num_folds):\n",
        "  run[\"Challenge score\"].append(challenge_score[i])\n",
        "  run[\"AUROC outcomes\"].append(auroc_outcomes[i])\n",
        "  run[\"AUPRC outcomes\"].append(auprc_outcomes[i])\n",
        "  run[\"Accuracy outcomes\"].append(accuracy_outcomes[i])\n",
        "  run[\"F measure outcomes\"].append(f_measure_outcomes[i])\n",
        "  run[\"MSE cpcs\"].append(mse_cpcs[i])\n",
        "  run[\"MAE cpcs\"].append(mae_cpcs[i])\n",
        "\n",
        "run.stop()"
      ],
      "metadata": {
        "id": "Vs5IGZjbgGJx"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}